{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate shannon entropy\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featureVec in dataSet:\n",
    "        currentLabel = featureVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob,2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate dataset for testing\n",
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet=[]\n",
    "    for featureVec in dataSet:\n",
    "        if featureVec[axis] == value:\n",
    "            reducedFeatureVec = featureVec[:axis]\n",
    "            reducedFeatureVec.extend(featureVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatureVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    #We need this because information gain need this base entropy to substract\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featureList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featureList)\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet) / float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if(infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return the category with most frequency\n",
    "\"\"\"\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classCount:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "        sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet, labels):\n",
    "    #Get all labels\n",
    "    classList = [entry[-1] for entry in dataSet]\n",
    "    #If categories are the same, stop creating tree\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    #Return label with most frequency\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    #Pick best feature using previous algorithm\n",
    "    bestFeature = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatureLabel = labels[bestFeature]\n",
    "    myTree = {bestFeatureLabel: {}}\n",
    "    del(labels[bestFeature])\n",
    "    featureValues = [entry[bestFeature] for entry in dataSet]\n",
    "    #Get cardinality\n",
    "    uniqueVals = set(featureValues)\n",
    "    for value in uniqueVals:\n",
    "        #Copy label\n",
    "        subLabels = labels[:]\n",
    "        #Recursively call createTree()\n",
    "        myTree[bestFeatureLabel][value] = createTree(splitDataSet(dataSet, bestFeature, value), subLabels)\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet, label = createDataSet()\n",
    "dataSet_origin, label_origin = createDataSet()\n",
    "myTree= createTree(dataSet, label)\n",
    "myTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Example***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    key = testVec[featIndex]\n",
    "    valueOfFeat = secondDict[key]\n",
    "    if isinstance(valueOfFeat, dict): \n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else: classLabel = valueOfFeat\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree predicts that  [1 0] belongs to no\n",
      "Decision tree predicts that  [1 0] belongs to no\n",
      "Decision tree predicts that  [0 0] belongs to no\n",
      "Decision tree predicts that  [1 1] belongs to yes\n",
      "Decision tree predicts that  [1 1] belongs to yes\n",
      "Decision tree predicts that  [0 0] belongs to no\n",
      "Decision tree predicts that  [1 1] belongs to yes\n",
      "Decision tree predicts that  [1 0] belongs to no\n",
      "Decision tree predicts that  [0 1] belongs to no\n",
      "Decision tree predicts that  [1 1] belongs to yes\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    firstFeat = random.randint(0,2)\n",
    "    secondFeat = random.randint(0,2)\n",
    "    input = np.array([firstFeat, secondFeat])\n",
    "    prediction = classifyDT(myTree, label_origin, input)\n",
    "    print('Decision tree predicts that ', input, 'belongs to', prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
