{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building data set..\n",
      "X [[1600, 26.4, 51.0, 31.0, 48.0, 34.0, 2.7, -0.44, 2.25, 112.6, 110.0, 2.6, 101.6, 0.312, 0.342, 0.574, 0.532, 12.9, 24.5, 0.24100000000000002, 0.512, 11.1, 78.6, 0.20600000000000002, 838342.0, 20447.0, 41.7, 91.5, 0.455, 10.3, 30.0, 0.342, 31.4, 61.5, 0.511, 18.8, 24.5, 0.768, 10.0, 33.5, 43.5, 23.4, 7.7, 4.1, 12.7, 22.1, 112.5, 41.5, 88.2, 0.47100000000000003, 10.8, 30.2, 0.359, 30.7, 58.0, 0.529, 21.2, 27.5, 0.7709999999999999, 10.9, 36.9, 47.8, 26.9, 7.4, 5.3, 14.9, 21.3, 115.2, 1700, 25.7, 49.0, 33.0, 52.0, 30.0, 4.44, -0.54, 3.9, 112.2, 107.8, 4.4, 99.6, 0.215, 0.381, 0.5670000000000001, 0.534, 11.5, 21.6, 0.17300000000000001, 0.514, 13.4, 77.0, 0.198, 763584.0, 18624.0, 39.5, 88.1, 0.44799999999999995, 11.5, 33.5, 0.344, 28.0, 54.6, 0.513, 17.4, 22.8, 0.764, 10.4, 35.5, 45.9, 23.7, 6.8, 3.9, 15.1, 19.5, 108.0, 42.1, 90.5, 0.465, 12.6, 34.5, 0.365, 29.5, 56.0, 0.527, 15.6, 19.5, 0.802, 9.8, 34.7, 44.5, 26.3, 8.6, 5.3, 12.8, 20.4, 112.4]]\n",
      "Fitting on 1230 game samples..\n",
      "Doing cross-validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python demo\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6546442713237286\n",
      "Doing log loss test...\n",
      "0.6041205630631618\n",
      "Predicting on new schedule..\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "base_elo = 1600\n",
    "team_elos = {} \n",
    "team_stats = {}\n",
    "X = []\n",
    "y = []\n",
    "#data directory\n",
    "folder = 'data2018'\n",
    "\n",
    "\n",
    "def initialize_data(Mstat, Ostat, Tstat):\n",
    "    new_Mstat = Mstat.drop(['Rk', 'Arena'], axis=1)\n",
    "    new_Ostat = Ostat.drop(['Rk', 'G', 'MP'], axis=1)\n",
    "    new_Tstat = Tstat.drop(['Rk', 'G', 'MP'], axis=1)\n",
    "\n",
    "    team_stats1 = pd.merge(new_Mstat, new_Ostat, how='left', on='Team')\n",
    "    team_stats1 = pd.merge(team_stats1, new_Tstat, how='left', on='Team')\n",
    "    return team_stats1.set_index('Team', inplace=False, drop=True)\n",
    "\n",
    "def get_elo(team):\n",
    "    try:\n",
    "        return team_elos[team]\n",
    "    except:\n",
    "        # give each team a base elo score there is not any\n",
    "        team_elos[team] = base_elo\n",
    "        return team_elos[team]\n",
    "\n",
    "#Calculate the Elo score for each team\n",
    "def calc_elo(win_team, lose_team):\n",
    "    winner_rank = get_elo(win_team)\n",
    "    loser_rank = get_elo(lose_team)\n",
    "\n",
    "    rank_diff = winner_rank - loser_rank\n",
    "    exp = (rank_diff  * -1) / 400\n",
    "    odds = 1 / (1 + math.pow(10, exp))\n",
    "    # modify k value based on rank\n",
    "    if winner_rank < 2100:\n",
    "        k = 32\n",
    "    elif winner_rank >= 2100 and winner_rank < 2400:\n",
    "        k = 24\n",
    "    else:\n",
    "        k = 16\n",
    "    \n",
    "    # update rank value\n",
    "    new_winner_rank = round(winner_rank + (k * (1 - odds)))      \n",
    "    new_loser_rank = round(loser_rank + (k * (0 - odds)))\n",
    "    return new_winner_rank, new_loser_rank\n",
    "\n",
    "def  build_dataSet(all_data):\n",
    "    print(\"Building data set..\")\n",
    "    X = []\n",
    "    skip = 0\n",
    "    for index, row in all_data.iterrows():\n",
    "\n",
    "        Wteam = row['WTeam']\n",
    "        Lteam = row['LTeam']\n",
    "\n",
    "        # Get initial elo score for each team\n",
    "        team1_elo = get_elo(Wteam)\n",
    "        team2_elo = get_elo(Lteam)\n",
    "\n",
    "        # add 100 elo points to home team\n",
    "        if row['WLoc'] == 'H':\n",
    "            team1_elo += 100\n",
    "        else:\n",
    "            team2_elo += 100\n",
    "\n",
    "        # take elo as the eigenvector\n",
    "        team1_features = [team1_elo]\n",
    "        team2_features = [team2_elo]\n",
    "\n",
    "        # Add stats from BasketballReference.com\n",
    "        for key, value in team_stats.loc[Wteam].iteritems():\n",
    "            team1_features.append(value)\n",
    "        for key, value in team_stats.loc[Lteam].iteritems():\n",
    "            team2_features.append(value)\n",
    "\n",
    "        # Randomly distribute the eigenvector of both teams on both side of game stats\n",
    "        # and assign the corresponding value of 0 or 1\n",
    "        if random.random() > 0.5:\n",
    "            X.append(team1_features + team2_features)\n",
    "            y.append(0)\n",
    "        else:\n",
    "            X.append(team2_features + team1_features)\n",
    "            y.append(1)\n",
    "\n",
    "        if skip == 0:\n",
    "            print('X',X)\n",
    "            skip = 1\n",
    "\n",
    "        # update elo score\n",
    "        new_winner_rank, new_loser_rank = calc_elo(Wteam, Lteam)\n",
    "        team_elos[Wteam] = new_winner_rank\n",
    "        team_elos[Lteam] = new_loser_rank\n",
    "\n",
    "    return np.nan_to_num(X), y\n",
    "\n",
    "def predict_winner(team_1, team_2, model):\n",
    "    features = []\n",
    "\n",
    "    # Visitor\n",
    "    features.append(get_elo(team_1))\n",
    "    for key, value in team_stats.loc[team_1].iteritems():\n",
    "        features.append(value)\n",
    "\n",
    "    # Home\n",
    "    features.append(get_elo(team_2) + 100)\n",
    "    for key, value in team_stats.loc[team_2].iteritems():\n",
    "        features.append(value)\n",
    "\n",
    "    features = np.nan_to_num(features)\n",
    "    return model.predict_proba([features])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    Mstat = pd.read_csv(folder + '/Miscellaneous_Stat.csv')\n",
    "    Ostat = pd.read_csv(folder + '/Opponent_Per_Game_Stat.csv')\n",
    "    Tstat = pd.read_csv(folder + '/Team_Per_Game_Stat.csv')\n",
    "\n",
    "    team_stats = initialize_data(Mstat, Ostat, Tstat)\n",
    "\n",
    "    result_data = pd.read_csv(folder + '/Result.csv')\n",
    "    X, y = build_dataSet(result_data)\n",
    "\n",
    "    # Train model\n",
    "    print(\"Fitting on %d game samples..\" % len(X))\n",
    "\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    print(\"Doing cross-validation..\")\n",
    "    print(cross_val_score(model, X, y, cv = 10, scoring='accuracy', n_jobs=-1).mean())\n",
    "    print('Doing log loss test...')\n",
    "    print(log_loss(y, model.predict_proba(X)))\n",
    "    print('Predicting on new schedule..')\n",
    "    schedule1617 = pd.read_csv(folder + '/2019-2020Schedule.csv')\n",
    "    result = []\n",
    "    for index, row in schedule1617.iterrows():\n",
    "        team1 = row['Vteam']\n",
    "        team2 = row['Hteam']\n",
    "        pred = predict_winner(team1, team2, model)\n",
    "        prob = pred[0][0]\n",
    "        if prob > 0.5:\n",
    "            winner = team1\n",
    "            loser = team2\n",
    "            result.append([winner, loser, prob])\n",
    "        else:\n",
    "            winner = team2\n",
    "            loser = team1\n",
    "            result.append([winner, loser, 1 - prob])\n",
    "\n",
    "    with open('19-20Result.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['win', 'lose', 'probability'])\n",
    "        writer.writerows(result)\n",
    "        print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
