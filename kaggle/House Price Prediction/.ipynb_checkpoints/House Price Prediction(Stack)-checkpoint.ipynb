{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up sns\n",
    "sns.set(style='white',context='notebook',palette='deep')\n",
    "colors=['#66c2ff','#5cd6d6','#c2c2d6','#00cc99','#ffd966','#dab3ff']\n",
    "sns.set_palette(palette=colors,n_colors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "\n",
    "train.drop('Id', axis=1, inplace=True)\n",
    "test.drop('Id', axis=1, inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "g = sns.regplot(x=train['GrLivArea'], y=train['SalePrice'], fit_reg=False).set_title('Before removing outlier')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "train = train.drop(train[(train['GrLivArea'] > 4000)].index)\n",
    "g = sns.regplot(x=train['GrLivArea'], y=train['SalePrice'], fit_reg=False).set_title('After removing outlier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First combine two dataset into one for easier imputation\n",
    "rtrain = train.shape[0]\n",
    "rtest = test.shape[0]\n",
    "\n",
    "#Store SalePrice and remove\n",
    "y_train = train['SalePrice']\n",
    "\n",
    "combined = pd.concat((train, test)).reset_index(drop=True)\n",
    "combined.drop(['SalePrice'],axis=1, inplace=True)\n",
    "print('Shape of combined dataset: ', combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_na = combined.isnull().sum()\n",
    "combined_na = combined_na.drop(combined_na[combined_na == 0].index).sort_values(ascending=False)\n",
    "plt.subplots(figsize=(15,10))\n",
    "combined_na.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMissing():\n",
    "    combined_na = combined.isnull().sum()\n",
    "    print('Features with missing value: ', combined_na.drop(combined_na[combined_na==0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ('PoolQC', 'MiscFeature','Alley','Fence','FireplaceQu','GarageQual','GarageType','GarageFinish','GarageCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','MSSubClass','MasVnrType'):\n",
    "    combined[feature] = combined[feature].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LotFrontage'] = combined.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in ('GarageYrBlt', 'GarageArea','GarageCars','BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF','MasVnrArea','BsmtFullBath','BsmtHalfBath'):\n",
    "    combined[feature] = combined[feature].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For these features with just a few missing value below, fill in with their most frequent value\n",
    "def imputeMode(feature):\n",
    "    mode = combined[feature].value_counts().index[0]\n",
    "    combined[feature] = combined[feature].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputeMode('MSZoning')\n",
    "imputeMode('Electrical')\n",
    "imputeMode('KitchenQual')\n",
    "imputeMode('Exterior1st')\n",
    "imputeMode('Exterior2nd')\n",
    "imputeMode('SaleType')\n",
    "imputeMode('Functional')\n",
    "print('Imputation Mode Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkMissing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a closer inpect on how Utilities feature behave\n",
    "plt.subplots(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "g = sns.countplot(x='Utilities', data=train).set_title('Utilities from training data')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "g = sns.countplot(x='Utilities', data=test).set_title('Utilities from testing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since in the testing data the Utilities feature doesn't vary so we'll drop this data.\n",
    "combined = combined.drop('Utilities', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkMissing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce correlation heatmap\n",
    "corr = train.corr()\n",
    "plt.subplots(figsize=(30,30))\n",
    "sns.heatmap(corr,vmax=1, vmin=0,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top influencing features would get polynomials\n",
    "feat_poly = ['OverallQual','GrLivArea','GarageCars',\n",
    "             'GarageArea','TotalBsmtSF','1stFlrSF',\n",
    "             'FullBath','TotRmsAbvGrd','Fireplaces',\n",
    "             'MasVnrArea','BsmtFinSF1','LotFrontage',\n",
    "             'WoodDeckSF','OpenPorchSF','2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feat_poly:\n",
    "    combined[feature + '-2'] = combined[feature] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feat_poly:\n",
    "    combined[feature + '-3'] = combined[feature] ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in feat_poly:\n",
    "    combined[feature + '-4'] = combined[feature] ** 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePlots(feature, order=None):\n",
    "    if order==True:\n",
    "        plot_order=train[feature].value_counts().sort_values(ascending=True).index\n",
    "    else:plot_order=order\n",
    "    plt.subplots(figsize=(20,5))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    sns.boxplot(x=feature, y='SalePrice', data=train, order=plot_order)\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    sns.stripplot(x=feature, y='SalePrice',data=train, size=5, jitter=True, order=plot_order)\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    sns.barplot(x=feature, y='SalePrice', data=train, order=plot_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BsmtQual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('BsmtQual',['Fa','TA','Gd','Ex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['BsmtQual'] = combined['BsmtQual'].map({'None':0, \"Fa\":1,\"TA\":2,\"Gd\":3,\"Ex\":4})\n",
    "combined['BsmtQual'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BsmtCond*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('BsmtCond',['Po','Fa','TA','Gd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['BsmtCond'] = combined['BsmtCond'].map({'None':0, \"Po\":1,\"Fa\":2,\"TA\":3,\"Gd\":4, 'Ex':5})\n",
    "combined['BsmtCond'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BsmtExposure*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('BsmtExposure',['No','Mn','Av','Gd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['BsmtExposure'] = combined['BsmtExposure'].map({'None':0, \"No\":1,\"Mn\":2,\"Av\":3,\"Gd\":4})\n",
    "combined['BsmtExposure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BsmtFinType1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('BsmtFinType1',['Unf','LwQ','Rec','BLQ','ALQ','GLQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=['BsmtFinType1'],prefix='BsmtFinType1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BsmtFinSF1 * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['BsmtFinSF1_Band'] = pd.cut(combined['BsmtFinSF1'],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['BsmtFinSF1_Band'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[combined['BsmtFinSF1']<=1002.5, 'BsmtFinSF1'] = 1\n",
    "combined.loc[(combined['BsmtFinSF1']>1002.5) & (combined['BsmtFinSF1'] <= 2005),'BsmtFinSF1'] = 2\n",
    "combined.loc[(combined['BsmtFinSF1']>2005) & (combined['BsmtFinSF1'] <= 3007.5),'BsmtFinSF1'] = 3\n",
    "combined.loc[(combined['BsmtFinSF1']>3007.5) & (combined['BsmtFinSF1'] <= 4010),'BsmtFinSF1'] = 4\n",
    "\n",
    "combined['BsmtFinSF1'] = combined['BsmtFinSF1'].astype(int)\n",
    "combined.drop('BsmtFinSF1_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns=['BsmtFinSF1'], prefix='BsmtFinSF1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BsmtFinType2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('BsmtFinType2',['Unf','LwQ','Rec','BLQ','ALQ','GLQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=['BsmtFinType2'], prefix='BsmtFinType2')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BsmtFinSF2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['BsmtFinSF2_Flag'] = combined['BsmtFinSF2'].map(lambda x: 0 if x == 0 else 1)\n",
    "combined.drop('BsmtFinSF2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BsmtUnfSF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['BsmtUnfSF_Band'] = pd.cut(combined['BsmtUnfSF'],3)\n",
    "combined['BsmtUnfSF_Band'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[combined['BsmtUnfSF']<=778.667, 'BsmtUnfSF'] = 1\n",
    "combined.loc[(combined['BsmtUnfSF']>778.667) & (combined['BsmtUnfSF'] <= 1557.333),'BsmtUnfSF'] = 2\n",
    "combined.loc[(combined['BsmtUnfSF']>1557.333) & (combined['BsmtUnfSF'] <= 2336),'BsmtUnfSF'] = 3\n",
    "\n",
    "combined['BsmtUnfSF'] = combined['BsmtUnfSF'].astype(int)\n",
    "combined.drop('BsmtUnfSF_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns=['BsmtUnfSF'], prefix='BsmtUnfSF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TotalBsmtSF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['TotalBsmtSF_Band'] = pd.cut(combined['TotalBsmtSF'], 10)\n",
    "combined['TotalBsmtSF_Band'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[combined['TotalBsmtSF']<=509.5, 'TotalBsmtSF'] = 1\n",
    "combined.loc[(combined['TotalBsmtSF']>509.5) & (combined['TotalBsmtSF']<=1019), 'TotalBsmtSF'] = 2\n",
    "combined.loc[(combined['TotalBsmtSF']>1019) & (combined['TotalBsmtSF']<=1528.5), 'TotalBsmtSF'] = 3\n",
    "combined.loc[(combined['TotalBsmtSF']>1528.5) & (combined['TotalBsmtSF']<=2038), 'TotalBsmtSF'] = 4\n",
    "combined.loc[(combined['TotalBsmtSF']>2038) & (combined['TotalBsmtSF']<=2547.5), 'TotalBsmtSF'] = 5\n",
    "combined.loc[(combined['TotalBsmtSF']>2547.5) & (combined['TotalBsmtSF']<=3057), 'TotalBsmtSF'] = 6\n",
    "combined.loc[(combined['TotalBsmtSF']>3057) & (combined['TotalBsmtSF']<=3566.5), 'TotalBsmtSF'] = 7\n",
    "combined.loc[combined['TotalBsmtSF']>3566.5, 'TotalBsmtSF'] = 8\n",
    "combined['TotalBsmtSF'] = combined['TotalBsmtSF'].astype(int)\n",
    "\n",
    "combined.drop('TotalBsmtSF_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"TotalBsmtSF\"], prefix=\"TotalBsmtSF\")\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binStep1(feature, num_bin):\n",
    "    combined[feature + '_Band'] = pd.cut(combined[feature], num_bin)\n",
    "    combined[feature + \"_Band\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binStep2(feature, target, minVal=None, maxVal=None):\n",
    "    if minVal == None and maxVal != None:\n",
    "        combined.loc[combined[feature]<= maxVal, feature] = target\n",
    "    elif maxVal == None and minVal != None:\n",
    "        combined.loc[combined[feature]>minVal, feature] = target\n",
    "    else:\n",
    "        combined.loc[(combined[feature]>minVal) & (combined[feature]<=maxVal), feature] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binStep3(feature):\n",
    "    combined[feature] = combined[feature].astype(int)\n",
    "\n",
    "    combined.drop(feature + '_Band', axis=1, inplace=True)\n",
    "\n",
    "    combined = pd.get_dummies(combined, columns = [feature], prefix=feature)\n",
    "    combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1stFlrSF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['1stFlrSF_Band'] = pd.cut(combined['1stFlrSF'], 6)\n",
    "combined['1stFlrSF_Band'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[combined['1stFlrSF']<=1127.5, '1stFlrSF'] = 1\n",
    "combined.loc[(combined['1stFlrSF']>1127.5) & (combined['1stFlrSF']<=1921), '1stFlrSF'] = 2\n",
    "combined.loc[(combined['1stFlrSF']>1921) & (combined['1stFlrSF']<=2714.5), '1stFlrSF'] = 3\n",
    "combined.loc[(combined['1stFlrSF']>2714.5) & (combined['1stFlrSF']<=3508), '1stFlrSF'] = 4\n",
    "combined.loc[(combined['1stFlrSF']>3508) & (combined['1stFlrSF']<=4301.5), '1stFlrSF'] = 5\n",
    "combined.loc[combined['1stFlrSF']>4301.5, '1stFlrSF'] = 6\n",
    "combined['1stFlrSF'] = combined['1stFlrSF'].astype(int)\n",
    "\n",
    "combined.drop('1stFlrSF_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"1stFlrSF\"], prefix=\"1stFlrSF\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2ndFlrSF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = plt.GridSpec(2, 3, wspace=0.1, hspace=0.15)\n",
    "plt.subplots(figsize =(30, 15))\n",
    "\n",
    "plt.subplot(grid[0, 0])\n",
    "g = sns.regplot(x=train['2ndFlrSF'], y=train['SalePrice'], fit_reg=False, label = \"corr: %2f\"%(pearsonr(train['2ndFlrSF'], train['SalePrice'])[0]))\n",
    "g = g.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(grid[0, 1:])\n",
    "sns.boxplot(x=\"Neighborhood\", y=\"2ndFlrSF\", data=train, palette = colors)\n",
    "\n",
    "plt.subplot(grid[1, 0]);\n",
    "sns.barplot(x=\"BldgType\", y=\"2ndFlrSF\", data=train, palette = colors)\n",
    "\n",
    "plt.subplot(grid[1, 1]);\n",
    "sns.barplot(x=\"HouseStyle\", y=\"2ndFlrSF\", data=train, palette = colors)\n",
    "\n",
    "plt.subplot(grid[1, 2]);\n",
    "sns.barplot(x=\"LotShape\", y=\"2ndFlrSF\", data=train, palette = colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep1('2ndFlrSF', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('2ndFlrSF', 1, maxVal=310.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('2ndFlrSF', 2, minVal=310.333,maxVal=620.667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('2ndFlrSF', 3, minVal=620.667,maxVal=931)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('2ndFlrSF', 4, minVal=931,maxVal=1241.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('2ndFlrSF',5, minVal=1241.333,maxVal=1551.667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('2ndFlrSF', 6, minVal=1551.667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['2ndFlrSF'] = combined['2ndFlrSF'].astype(int)\n",
    "\n",
    "combined.drop('2ndFlrSF_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"2ndFlrSF\"], prefix=\"2ndFlrSF\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LowQualFinSF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LowQualFinSF_Flag'] = combined['LowQualFinSF'].map(lambda x : 0 if x==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.drop('LowQualFinSF', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sum of all bath rooms*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['TotalBathrooms'] = combined['BsmtHalfBath'] + combined['BsmtFullBath'] + combined['HalfBath'] + combined['FullBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['BsmtHalfBath','BsmtFullBath','HalfBath','FullBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BedRoom*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kitchen*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*KitchenQual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('KitchenQual', ['Fa','TA','Gd','Ex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['KitchenQual'] = combined['KitchenQual'].map({'Fa':1,\"TA\":2,\"Gd\":3,\"Ex\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['KitchenQual'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*FireplaceQu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('FireplaceQu',['Po','Fa','TA','Gd','Ex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['FireplaceQu'] = combined['FireplaceQu'].map({'None':0,'Po':1,'Fa':2,\"TA\":3,\"Gd\":4,\"Ex\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['FireplaceQu'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GrLivArea*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep1('GrLivArea', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GrLivArea', 1, maxVal=1127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GrLivArea', 2, minVal=1127.5, maxVal=1921)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GrLivArea', 3, minVal=1921, maxVal=2714.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GrLivArea', 4, minVal=2714.5, maxVal=3508)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GrLivArea', 5, minVal=3508, maxVal=4301.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GrLivArea', 6, minVal=4301.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['GrLivArea'] = combined['GrLivArea'].astype(int)\n",
    "\n",
    "combined.drop('GrLivArea_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"GrLivArea\"], prefix=\"GrLivArea\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MSSubClass*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('MSSubClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['MSSubClass'] = combined['MSSubClass'].astype(str)\n",
    "combined = pd.get_dummies(combined, columns = [\"MSSubClass\"], prefix=\"MSSubClass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*BlogType*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('BldgType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['BldgType'] = combined['BldgType'].astype(str)\n",
    "combined = pd.get_dummies(combined, columns=['BldgType'], prefix='BldgType')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*HouseStyle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('HouseStyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster those categories with similarity\n",
    "combined['HouseStyle'] = combined['HouseStyle'].map({\"2Story\":\"2Story\", \"1Story\":\"1Story\", \"1.5Fin\":\"1.5Story\", \"1.5Unf\":\"1.5Story\", \n",
    "                                                     \"SFoyer\":\"SFoyer\", \"SLvl\":\"SLvl\", \"2.5Unf\":\"2.5Story\", \"2.5Fin\":\"2.5Story\"})\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"HouseStyle\"], prefix=\"HouseStyle\")\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*OverallQual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('OverallQual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*OverallCond*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('OverallCond')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YearRemodAdd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('YearRemodAdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Remod_Diff'] = train['YearRemodAdd'] - train['YearBuilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Remod_Diff'] = combined['YearRemodAdd'] - combined['YearBuilt']\n",
    "combined.drop('YearRemodAdd', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YearBuilt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(50,30))\n",
    "sns.barplot(x='YearBuilt',y='SalePrice',data=train, palette=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep1('YearBuilt', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('YearBuilt',1,maxVal=1892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('YearBuilt',2,minVal=1892, maxVal=1911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('YearBuilt',3,minVal=1911, maxVal=1931)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('YearBuilt',4,minVal=1931, maxVal=1951)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('YearBuilt',5,minVal=1951, maxVal=1971)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('YearBuilt',6,minVal=1971, maxVal=1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('YearBuilt',7,minVal=1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['YearBuilt'] = combined['YearBuilt'].astype(int)\n",
    "\n",
    "combined.drop('YearBuilt_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"YearBuilt\"], prefix=\"YearBuilt\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Foundation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Foundation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined,columns=['Foundation'], prefix='Foundation')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Functional*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Functional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Functional'] = combined['Functional'].map({'Sev':1, 'Maj2':2, 'Maj1': 3, 'Mod':4, 'Min2':5,'Min1':6,'Typ':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Functional'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*RoofStyle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('RoofStyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"RoofStyle\"], prefix=\"RoofStyle\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*RoofMatl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('RoofMatl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"RoofMatl\"], prefix=\"RoofMatl\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exterior1st & Exterior2nd*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Exterior1st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Exterior2nd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Exter2(col):\n",
    "    if col['Exterior2nd'] == col['Exterior1st']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['ExteriorMatch_Flag'] = combined.apply(Exter2, axis=1)\n",
    "combined.drop('Exterior2nd', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"Exterior1st\"], prefix=\"Exterior1st\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MasVnrType*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('MasVnrType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=['MasVnrType'], prefix='MasVnrType')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MasVnrType*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since it's correlated highly with MasVnrType and doesn't vary much against SalesPrice, drop this\n",
    "combined.drop('MasVnrArea', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ExterQual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('ExterQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['ExterQual'] = combined['ExterQual'].map({\"Fa\":1,\"TA\":2,\"Gd\":3,\"Ex\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['ExterQual'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ExterCond*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('ExterCond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We observe an obvious order here but this order has no correlation with SalePrice we don't have to map\n",
    "combined = pd.get_dummies(combined, columns = [\"ExterCond\"], prefix=\"ExterCond\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GarageType*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('GarageType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"GarageType\"], prefix=\"GarageType\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GarageYrBlt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(50,10))\n",
    "sns.boxplot(x='GarageYrBlt',y='SalePrice',data=train,palette=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep1('GarageYrBlt', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GarageYrBlt',1,maxVal=1964)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GarageYrBlt',2,minVal=1964, maxVal=1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GarageYrBlt',3,minVal=1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['GarageYrBlt'] = combined['GarageYrBlt'].astype(int)\n",
    "\n",
    "combined.drop('GarageYrBlt_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"GarageYrBlt\"], prefix=\"GarageYrBlt\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GarageFinish*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('GarageFinish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=['GarageFinish'], prefix='GarageFinish')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GarageCars*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('GarageCars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GarageArea*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep1('GarageArea', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GarageArea',1, maxVal=496)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GarageArea',2, minVal=496, maxVal=992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('GarageArea',3, minVal=992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['GarageArea'] = combined['GarageArea'].astype(int)\n",
    "\n",
    "combined.drop('GarageArea_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"GarageArea\"], prefix=\"GarageArea\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GarageQual*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('GarageQual',['Po','Fa','TA','Gd','Ex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster is performed here\n",
    "combined['GarageQual'] = combined['GarageQual'].map({'None':'None', 'Po':'Low','Fa':'Low','TA':'TA','Gd':'High','Ex':'High'})\n",
    "combined['GarageQual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=['GarageQual'], prefix='GarageQual')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*GarageCond*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('GarageCond',['Po','Fa','TA','Gd','Ex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar distribution with GarageQual\n",
    "combined['GarageCond'] = combined['GarageCond'].map({'None':'None', 'Po':'Low','Fa':'Low','TA':'TA','Gd':'High','Ex':'High'})\n",
    "combined['GarageCond'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=['GarageCond'], prefix='GarageCond')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*WoodDeckSF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WoodDeckFlag(col):\n",
    "    if col['WoodDeckSF'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "combined['NoWoodDeck_Flag'] = combined.apply(WoodDeckFlag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep1('WoodDeckSF', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('WoodDeckSF',1,maxVal=356)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('WoodDeckSF',2,minVal=356,maxVal=712)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('WoodDeckSF',3, minVal=712, maxVal=1068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('WoodDeckSF',4,maxVal=1068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['WoodDeckSF'] = combined['WoodDeckSF'].astype(int)\n",
    "\n",
    "combined.drop('WoodDeckSF_Band', axis=1, inplace=True)\n",
    "combined = pd.get_dummies(combined, columns = [\"WoodDeckSF\"], prefix=\"WoodDeckSF\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['TotalPorchSF'] = combined['OpenPorchSF'] + combined['OpenPorchSF'] + combined['EnclosedPorch'] + combined['3SsnPorch'] + combined['ScreenPorch'] \n",
    "train['TotalPorchSF'] = train['OpenPorchSF'] + train['OpenPorchSF'] + train['EnclosedPorch'] + train['3SsnPorch'] + train['ScreenPorch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porchFlag(col):\n",
    "    if col['TotalPorchSF'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['NoPorch_Flag']= combined.apply(porchFlag, axis=1)\n",
    "binStep1('TotalPorchSF', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('TotalPorchSF', 1, maxVal=431)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('TotalPorchSF', 2, minVal=431, maxVal=862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('TotalPorchSF', 3, minVal=862, maxVal=1293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep2('TotalPorchSF', 4, minVal=1293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['TotalPorchSF'] = combined['TotalPorchSF'].astype(int)\n",
    "\n",
    "combined.drop('TotalPorchSF_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"TotalPorchSF\"], prefix=\"TotalPorchSF\")\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PoolArea*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PoolFlag(col):\n",
    "    if col['PoolArea'] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "combined['HasPool_Flag'] = combined.apply(PoolFlag, axis=1)\n",
    "combined.drop('PoolArea', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PoolQC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.drop('PoolQC',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fence*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Fence',['MnWw','GdWo','MnPrv','GdPrv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=['Fence'],prefix='Fence')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MSZoning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('MSZoning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns=['MSZoning'],prefix='MSZoning')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neighborhood*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Neighborhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For categorical feature without order, create dummy feature\n",
    "combined = pd.get_dummies(combined, columns=['Neighborhood'],prefix='Neighborhood')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Condition1&Condition2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Condition1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Condition2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Condition1'] = combined['Condition1'].map({\"Norm\":\"Norm\", \"Feedr\":\"Street\", \"PosN\":\"Pos\", \"Artery\":\"Street\", \"RRAe\":\"Train\",\n",
    "                                                    \"RRNn\":\"Train\", \"RRAn\":\"Train\", \"PosA\":\"Pos\", \"RRNe\":\"Train\"})\n",
    "combined['Condition2'] = combined['Condition2'].map({\"Norm\":\"Norm\", \"Feedr\":\"Street\", \"PosN\":\"Pos\", \"Artery\":\"Street\", \"RRAe\":\"Train\",\n",
    "                                                    \"RRNn\":\"Train\", \"RRAn\":\"Train\", \"PosA\":\"Pos\", \"RRNe\":\"Train\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConditionMatch(col):\n",
    "    if col['Condition1'] == col['Condition2']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "combined['Diff2ndCondition_Flag'] = combined.apply(ConditionMatch, axis=1)\n",
    "combined.drop('Condition2', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"Condition1\"], prefix=\"Condition1\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LotFrontage*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LotArea*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binStep1('LotArea', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [5684.75, 7474, 8520, 9450, 10355.25, 11554.25, 13613]\n",
    "binStep2('LotArea',1,maxVal=nums[0])\n",
    "binStep2('LotArea',2,minVal=nums[0], maxVal=nums[1])\n",
    "binStep2('LotArea',3,minVal=nums[1], maxVal=nums[2])\n",
    "binStep2('LotArea',4,minVal=nums[2], maxVal=nums[3])\n",
    "binStep2('LotArea',5,minVal=nums[3], maxVal=nums[4])\n",
    "binStep2('LotArea',6,minVal=nums[4], maxVal=nums[5])\n",
    "binStep2('LotArea',7,minVal=nums[5], maxVal=nums[6])\n",
    "binStep2('LotArea',8,minVal=nums[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LotArea'] = combined['LotArea'].astype(int)\n",
    "\n",
    "combined.drop('LotArea_Band', axis=1, inplace=True)\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"LotArea\"], prefix=\"LotArea\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LotShape*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('LotShape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"LotShape\"], prefix=\"LotShape\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LandContour*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('LandContour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"LandContour\"], prefix=\"LandContour\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LotConfig***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('LotConfig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LotConfig'] = combined['LotConfig'].map({\"Inside\":\"Inside\", \"FR2\":\"FR\", \"Corner\":\"Corner\", \"CulDSac\":\"CulDSac\", \"FR3\":\"FR\"})\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"LotConfig\"], prefix=\"LotConfig\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LandSlope*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('LandSlope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['LandSlope'] = combined['LandSlope'].map({\"Gtl\":1, \"Mod\":2, \"Sev\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Slope(col):\n",
    "    if col['LandSlope'] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "combined['GentleSlope_Flag'] = combined.apply(Slope, axis=1)\n",
    "combined.drop('LandSlope', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Street*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Street')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.drop('Street',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Alley*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Alley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"Alley\"], prefix=\"Alley\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PavedDrive*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('PavedDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"PavedDrive\"], prefix=\"PavedDrive\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Heating*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Heating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['GasA_Flag'] = combined['Heating'].map({\"GasA\":1, \"GasW\":0, \"Grav\":0, \"Wall\":0, \"OthW\":0, \"Floor\":0})\n",
    "combined.drop('Heating', axis=1, inplace=True)\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*HeatingQC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('HeatingQC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['HeatingQC'] = combined['HeatingQC'].map({\"Po\":1, \"Fa\":2, \"TA\":3, \"Gd\":4, \"Ex\":5})\n",
    "combined['HeatingQC'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CentralAir*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('CentralAir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['CentralAir'] = combined['CentralAir'].map({\"Y\":1, \"N\":0})\n",
    "combined['CentralAir'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Electrical*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('Electrical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Electrical'] = combined['Electrical'].map({\"SBrkr\":\"SBrkr\", \"FuseF\":\"Fuse\", \"FuseA\":\"Fuse\", \"FuseP\":\"Fuse\", \"Mix\":\"Mix\"})\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"Electrical\"], prefix=\"Electrical\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MiscFeature*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('MiscFeature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MiscFeature', 'MiscVal']\n",
    "combined.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MoSold*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('MoSold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"MoSold\"], prefix=\"MoSold\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YrSold*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('YrSold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"YrSold\"], prefix=\"YrSold\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SaleType*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('SaleType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['SaleType'] = combined['SaleType'].map({\"WD\":\"WD\", \"New\":\"New\", \"COD\":\"COD\", \"CWD\":\"CWD\", \"ConLD\":\"Oth\", \"ConLI\":\"Oth\", \n",
    "                                                 \"ConLw\":\"Oth\", \"Con\":\"Oth\", \"Oth\":\"Oth\"})\n",
    "\n",
    "combined = pd.get_dummies(combined, columns = [\"SaleType\"], prefix=\"SaleType\")\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SaleCondition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePlots('SaleCondition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.get_dummies(combined, columns = [\"SaleCondition\"], prefix=\"SaleCondition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,10))\n",
    "g = sns.distplot(train['SalePrice'], fit=norm, label='Skewness : %.2f'%train['SalePrice'].skew())\n",
    "g = g.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SalePrice'] = np.log1p(train['SalePrice'])\n",
    "y_train = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,10))\n",
    "g = sns.distplot(train['SalePrice'], fit=norm, label='Skewness : %.2f'%train['SalePrice'].skew())\n",
    "g = g.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating skewed features in numeric\n",
    "numeric_feats = combined.dtypes[combined.dtypes != 'object'].index\n",
    "skewed_feats = combined[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "\n",
    "plt.subplots(figsize=(65,30))\n",
    "skewed_feats.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Box-Cox\n",
    "skewness = skewed_feats[abs(skewed_feats) > 0.5]\n",
    "skewed_features = skewness.index\n",
    "lam=0.15\n",
    "for feat in skewed_features:\n",
    "    combined[feat] = boxcox1p(combined[feat], lam)\n",
    "print(skewness.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Modeling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined[:rtrain]\n",
    "test = combined[rtrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xbgr = xgb.XGBRegressor()\n",
    "xbgr.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(xbgr.feature_importances_)[::-1]\n",
    "indices = indices[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,15))\n",
    "g = sns.barplot(y=train.columns[indices], x = xbgr.feature_importances_[indices], orient='h', palette = colors)\n",
    "g.set_xlabel(\"Importance\", fontsize=12)\n",
    "g.set_ylabel(\"Features\", fontsize=12)\n",
    "g.tick_params(labelsize=9)\n",
    "g.set_title('XGB feature importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = train.copy()\n",
    "xgb_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = xgb.XGBRegressor()\n",
    "xgbr.fit(xgb_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_feat_red = SelectFromModel(xgbr, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb_feat_red.transform(xgb_train)\n",
    "xgb_test = xgb_feat_red.transform(xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feature reduction:')\n",
    "print('X_train: ', xgb_train.shape, 'X_test', xgb_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xgb_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1019, 45) X_test:  (437, 45) y_train:  (1019,) y_test:  (437,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ', X_train.shape, 'X_test: ', X_test.shape, 'y_train: ', y_train.shape, 'y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [KernelRidge(),ElasticNet(), Lasso(),GradientBoostingRegressor(),BayesianRidge(),LassoLarsIC(), RandomForestRegressor(), xgb.XGBRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuff = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  ['Name','Parameters','Train Accuracy Mean','Test Accuracy']\n",
    "before_model_compare = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 KernelRidge trained.\n",
      "2 ElasticNet trained.\n",
      "3 Lasso trained.\n",
      "4 GradientBoostingRegressor trained.\n",
      "5 BayesianRidge trained.\n",
      "6 LassoLarsIC trained.\n",
      "7 RandomForestRegressor trained.\n",
      "[15:40:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:40:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:40:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:40:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:40:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:40:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "8 XGBRegressor trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train Accuracy Mean</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Accuracy Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KernelRidge</td>\n",
       "      <td>{'alpha': 1, 'coef0': 1, 'degree': 3, 'gamma':...</td>\n",
       "      <td>31.517</td>\n",
       "      <td>32.314</td>\n",
       "      <td>32.313727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>22.118</td>\n",
       "      <td>22.629</td>\n",
       "      <td>22.628826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 1.0, 'copy_X': True, 'fit_intercept'...</td>\n",
       "      <td>27.129</td>\n",
       "      <td>27.394</td>\n",
       "      <td>27.394226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'criterion': 'friedman_mse', 'i...</td>\n",
       "      <td>12.732</td>\n",
       "      <td>12.414</td>\n",
       "      <td>12.414110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>{'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...</td>\n",
       "      <td>11.375</td>\n",
       "      <td>11.818</td>\n",
       "      <td>11.817548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoLarsIC</td>\n",
       "      <td>{'copy_X': True, 'criterion': 'aic', 'eps': 2....</td>\n",
       "      <td>11.569</td>\n",
       "      <td>11.757</td>\n",
       "      <td>11.757406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'mse', 'max_d...</td>\n",
       "      <td>14.403</td>\n",
       "      <td>14.899</td>\n",
       "      <td>14.899103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'cols...</td>\n",
       "      <td>12.514</td>\n",
       "      <td>12.332</td>\n",
       "      <td>12.331515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  \\\n",
       "0                KernelRidge   \n",
       "1                 ElasticNet   \n",
       "2                      Lasso   \n",
       "3  GradientBoostingRegressor   \n",
       "4              BayesianRidge   \n",
       "5                LassoLarsIC   \n",
       "6      RandomForestRegressor   \n",
       "7               XGBRegressor   \n",
       "\n",
       "                                          Parameters  Train Accuracy Mean  \\\n",
       "0  {'alpha': 1, 'coef0': 1, 'degree': 3, 'gamma':...               31.517   \n",
       "1  {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...               22.118   \n",
       "2  {'alpha': 1.0, 'copy_X': True, 'fit_intercept'...               27.129   \n",
       "3  {'alpha': 0.9, 'criterion': 'friedman_mse', 'i...               12.732   \n",
       "4  {'alpha_1': 1e-06, 'alpha_2': 1e-06, 'compute_...               11.375   \n",
       "5  {'copy_X': True, 'criterion': 'aic', 'eps': 2....               11.569   \n",
       "6  {'bootstrap': True, 'criterion': 'mse', 'max_d...               14.403   \n",
       "7  {'base_score': 0.5, 'booster': 'gbtree', 'cols...               12.514   \n",
       "\n",
       "   Test Accuracy  Test Accuracy Mean  \n",
       "0         32.314           32.313727  \n",
       "1         22.629           22.628826  \n",
       "2         27.394           27.394226  \n",
       "3         12.414           12.414110  \n",
       "4         11.818           11.817548  \n",
       "5         11.757           11.757406  \n",
       "6         14.899           14.899103  \n",
       "7         12.332           12.331515  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_index = 0\n",
    "for alg in models:\n",
    "    model_name = alg.__class__.__name__\n",
    "    before_model_compare.loc[row_index, 'Name'] = model_name\n",
    "    before_model_compare.loc[row_index, 'Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    alg.fit(X_train, y_train)\n",
    "    \n",
    "    training_re = np.sqrt((-cross_val_score(alg, X_train, y_train, cv=shuff, scoring='neg_mean_squared_error')).mean())\n",
    "    test_re = np.sqrt(((y_test-alg.predict(X_test)) ** 2).mean())\n",
    "    \n",
    "    before_model_compare.loc[row_index, 'Train Accuracy Mean'] = (training_re) * 100\n",
    "    before_model_compare.loc[row_index,'Test Accuracy Mean'] = (test_re) * 100\n",
    "    \n",
    "    row_index += 1\n",
    "    print(row_index, alg.__class__.__name__, 'trained.')\n",
    "\n",
    "decimals = 3\n",
    "before_model_compare['Train Accuracy Mean'] = before_model_compare['Train Accuracy Mean'].apply(lambda x: round(x, decimals))\n",
    "before_model_compare['Test Accuracy'] = before_model_compare['Test Accuracy Mean'].apply(lambda x: round(x, decimals))\n",
    "before_model_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 KernelRidge trained...\n",
      "2 ElasticNet trained...\n",
      "3 Lasso trained...\n",
      "4 GradientBoostingRegressor trained...\n",
      "5 BayesianRidge trained...\n",
      "6 LassoLarsIC trained...\n",
      "7 RandomForestRegressor trained...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:44:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "8 XGBRegressor trained...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Train Accuracy Mean</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KernelRidge</td>\n",
       "      <td>{'alpha': 0.1, 'coef0': 100, 'degree': 1, 'gam...</td>\n",
       "      <td>11.376</td>\n",
       "      <td>11.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>{'alpha': 0.001, 'copy_X': True, 'fit_intercep...</td>\n",
       "      <td>11.487</td>\n",
       "      <td>12.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>{'alpha': 0.0005, 'copy_X': True, 'fit_interce...</td>\n",
       "      <td>11.465</td>\n",
       "      <td>11.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'huber', 'max_d...</td>\n",
       "      <td>12.107</td>\n",
       "      <td>12.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>{'alpha_1': 1e-08, 'alpha_2': 5e-06, 'copy_X':...</td>\n",
       "      <td>11.375</td>\n",
       "      <td>11.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoLarsIC</td>\n",
       "      <td>{'copy_X': True, 'criterion': 'aic', 'eps': 1e...</td>\n",
       "      <td>11.569</td>\n",
       "      <td>11.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': None, 'max_features': 'auto', 'm...</td>\n",
       "      <td>13.644</td>\n",
       "      <td>14.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'booster': 'gbtree', 'colsample_bylevel': 0.2...</td>\n",
       "      <td>12.208</td>\n",
       "      <td>11.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  \\\n",
       "0                KernelRidge   \n",
       "1                 ElasticNet   \n",
       "2                      Lasso   \n",
       "3  GradientBoostingRegressor   \n",
       "4              BayesianRidge   \n",
       "5                LassoLarsIC   \n",
       "6      RandomForestRegressor   \n",
       "7               XGBRegressor   \n",
       "\n",
       "                                          Parameters  Train Accuracy Mean  \\\n",
       "0  {'alpha': 0.1, 'coef0': 100, 'degree': 1, 'gam...               11.376   \n",
       "1  {'alpha': 0.001, 'copy_X': True, 'fit_intercep...               11.487   \n",
       "2  {'alpha': 0.0005, 'copy_X': True, 'fit_interce...               11.465   \n",
       "3  {'learning_rate': 0.1, 'loss': 'huber', 'max_d...               12.107   \n",
       "4  {'alpha_1': 1e-08, 'alpha_2': 5e-06, 'copy_X':...               11.375   \n",
       "5  {'copy_X': True, 'criterion': 'aic', 'eps': 1e...               11.569   \n",
       "6  {'max_depth': None, 'max_features': 'auto', 'm...               13.644   \n",
       "7  {'booster': 'gbtree', 'colsample_bylevel': 0.2...               12.208   \n",
       "\n",
       "   Test Accuracy  \n",
       "0         11.923  \n",
       "1         12.002  \n",
       "2         11.907  \n",
       "3         12.291  \n",
       "4         11.818  \n",
       "5         11.757  \n",
       "6         14.140  \n",
       "7         11.950  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [KernelRidge(), ElasticNet(), Lasso(), GradientBoostingRegressor(), BayesianRidge(), LassoLarsIC(), RandomForestRegressor(), xgb.XGBRegressor()]\n",
    "\n",
    "KR_param_grid = {'alpha': [0.1], 'coef0': [100], 'degree': [1], 'gamma': [None], 'kernel': ['polynomial']}\n",
    "EN_param_grid = {'alpha': [0.001], 'copy_X': [True], 'l1_ratio': [0.6], 'fit_intercept': [True], 'normalize': [False], \n",
    "                         'precompute': [False], 'max_iter': [300], 'tol': [0.001], 'selection': ['random'], 'random_state': [None]}\n",
    "LASS_param_grid = {'alpha': [0.0005], 'copy_X': [True], 'fit_intercept': [True], 'normalize': [False], 'precompute': [False], \n",
    "                    'max_iter': [300], 'tol': [0.01], 'selection': ['random'], 'random_state': [None]}\n",
    "GB_param_grid = {'loss': ['huber'], 'learning_rate': [0.1], 'n_estimators': [300], 'max_depth': [3], \n",
    "                                        'min_samples_split': [0.0025], 'min_samples_leaf': [5]}\n",
    "BR_param_grid = {'n_iter': [200], 'tol': [0.00001], 'alpha_1': [0.00000001], 'alpha_2': [0.000005], 'lambda_1': [0.000005], \n",
    "                 'lambda_2': [0.00000001], 'copy_X': [True]}\n",
    "LL_param_grid = {'criterion': ['aic'], 'normalize': [True], 'max_iter': [100], 'copy_X': [True], 'precompute': ['auto'], 'eps': [0.000001]}\n",
    "RFR_param_grid = {'n_estimators': [50], 'max_features': ['auto'], 'max_depth': [None], 'min_samples_split': [5], 'min_samples_leaf': [2]}\n",
    "XGB_param_grid = {'max_depth': [3], 'learning_rate': [0.1], 'n_estimators': [300], 'booster': ['gbtree'], 'gamma': [0], 'reg_alpha': [0.1],\n",
    "                  'reg_lambda': [0.7], 'max_delta_step': [0], 'min_child_weight': [1], 'colsample_bytree': [0.5], 'colsample_bylevel': [0.2],\n",
    "                  'scale_pos_weight': [1]}\n",
    "params_grid = [KR_param_grid, EN_param_grid, LASS_param_grid, GB_param_grid, BR_param_grid, LL_param_grid, RFR_param_grid, XGB_param_grid]\n",
    "\n",
    "after_model_compare = pd.DataFrame(columns = columns)\n",
    "\n",
    "row_index = 0\n",
    "for alg in models:\n",
    "    \n",
    "    gs_alg = GridSearchCV(alg, param_grid = params_grid[0], cv = shuff, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "    params_grid.pop(0)\n",
    "\n",
    "    #set name and parameters\n",
    "    model_name = alg.__class__.__name__\n",
    "    after_model_compare.loc[row_index, 'Name'] = model_name\n",
    "    \n",
    "    gs_alg.fit(X_train, y_train)\n",
    "    gs_best = gs_alg.best_estimator_\n",
    "    after_model_compare.loc[row_index, 'Parameters'] = str(gs_alg.best_params_)\n",
    "    \n",
    "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    after_training_results = np.sqrt(-gs_alg.best_score_)\n",
    "    after_test_results = np.sqrt(((y_test-gs_alg.predict(X_test))**2).mean())\n",
    "    \n",
    "    after_model_compare.loc[row_index, 'Train Accuracy Mean'] = (after_training_results)*100\n",
    "    after_model_compare.loc[row_index, 'Test Accuracy'] = (after_test_results)*100\n",
    "    \n",
    "    row_index+=1\n",
    "    print(row_index, alg.__class__.__name__, 'trained...')\n",
    "\n",
    "decimals = 3\n",
    "after_model_compare['Train Accuracy Mean'] = after_model_compare['Train Accuracy Mean'].apply(lambda x: round(x, decimals))\n",
    "after_model_compare['Test Accuracy'] = after_model_compare['Test Accuracy'].apply(lambda x: round(x, decimals))\n",
    "after_model_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Stacking*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 KernelRidge predictions added to stacking validation dataset...\n",
      "1 KernelRidge predictions added to stacking test dataset...\n",
      "--------------------------------------------------\n",
      "2 ElasticNet predictions added to stacking validation dataset...\n",
      "2 ElasticNet predictions added to stacking test dataset...\n",
      "--------------------------------------------------\n",
      "3 Lasso predictions added to stacking validation dataset...\n",
      "3 Lasso predictions added to stacking test dataset...\n",
      "--------------------------------------------------\n",
      "4 GradientBoostingRegressor predictions added to stacking validation dataset...\n",
      "4 GradientBoostingRegressor predictions added to stacking test dataset...\n",
      "--------------------------------------------------\n",
      "5 BayesianRidge predictions added to stacking validation dataset...\n",
      "5 BayesianRidge predictions added to stacking test dataset...\n",
      "--------------------------------------------------\n",
      "6 LassoLarsIC predictions added to stacking validation dataset...\n",
      "6 LassoLarsIC predictions added to stacking test dataset...\n",
      "--------------------------------------------------\n",
      "7 RandomForestRegressor predictions added to stacking validation dataset...\n",
      "7 RandomForestRegressor predictions added to stacking test dataset...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "8 XGBRegressor predictions added to stacking validation dataset...\n",
      "8 XGBRegressor predictions added to stacking test dataset...\n",
      "--------------------------------------------------\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "models = [KernelRidge(), ElasticNet(), Lasso(), GradientBoostingRegressor(), BayesianRidge(), LassoLarsIC(), RandomForestRegressor(), xgb.XGBRegressor()]\n",
    "names = ['KernelRidge', 'ElasticNet', 'Lasso', 'Gradient Boosting', 'Bayesian Ridge', 'Lasso Lars IC', 'Random Forest', 'XGBoost']\n",
    "params_grid = [KR_param_grid, EN_param_grid, LASS_param_grid, GB_param_grid, BR_param_grid, LL_param_grid, RFR_param_grid, XGB_param_grid]\n",
    "stacked_validation_train = pd.DataFrame()\n",
    "stacked_test_train = pd.DataFrame()\n",
    "\n",
    "row_index=0\n",
    "\n",
    "for alg in models:\n",
    "    \n",
    "    gs_alg = GridSearchCV(alg, param_grid = params_grid[0], cv = shuff, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "    params_grid.pop(0)\n",
    "    \n",
    "    gs_alg.fit(X_train, y_train)\n",
    "    gs_best = gs_alg.best_estimator_\n",
    "    stacked_validation_train.insert(loc = row_index, column = names[0], value = gs_best.predict(X_test))\n",
    "    print(row_index+1, alg.__class__.__name__, 'predictions added to stacking validation dataset...')\n",
    "    \n",
    "    stacked_test_train.insert(loc = row_index, column = names[0], value = gs_best.predict(xgb_test))\n",
    "    print(row_index+1, alg.__class__.__name__, 'predictions added to stacking test dataset...')\n",
    "    print(\"-\"*50)\n",
    "    names.pop(0)\n",
    "    \n",
    "    row_index+=1\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KernelRidge</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <th>Lasso Lars IC</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.097838</td>\n",
       "      <td>12.099544</td>\n",
       "      <td>12.099655</td>\n",
       "      <td>12.109385</td>\n",
       "      <td>12.096525</td>\n",
       "      <td>12.100640</td>\n",
       "      <td>12.133759</td>\n",
       "      <td>12.120995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.967256</td>\n",
       "      <td>11.966463</td>\n",
       "      <td>11.966292</td>\n",
       "      <td>12.041172</td>\n",
       "      <td>11.972548</td>\n",
       "      <td>11.977517</td>\n",
       "      <td>12.074685</td>\n",
       "      <td>12.041072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.798861</td>\n",
       "      <td>11.804574</td>\n",
       "      <td>11.809964</td>\n",
       "      <td>11.854919</td>\n",
       "      <td>11.806828</td>\n",
       "      <td>11.809399</td>\n",
       "      <td>11.861684</td>\n",
       "      <td>11.829997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.827207</td>\n",
       "      <td>11.818461</td>\n",
       "      <td>11.823268</td>\n",
       "      <td>11.827363</td>\n",
       "      <td>11.832695</td>\n",
       "      <td>11.851603</td>\n",
       "      <td>11.700799</td>\n",
       "      <td>11.768791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.275378</td>\n",
       "      <td>11.256968</td>\n",
       "      <td>11.261051</td>\n",
       "      <td>11.140688</td>\n",
       "      <td>11.276457</td>\n",
       "      <td>11.290995</td>\n",
       "      <td>11.350956</td>\n",
       "      <td>11.275813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   KernelRidge  ElasticNet      Lasso  Gradient Boosting  Bayesian Ridge  \\\n",
       "0    12.097838   12.099544  12.099655          12.109385       12.096525   \n",
       "1    11.967256   11.966463  11.966292          12.041172       11.972548   \n",
       "2    11.798861   11.804574  11.809964          11.854919       11.806828   \n",
       "3    11.827207   11.818461  11.823268          11.827363       11.832695   \n",
       "4    11.275378   11.256968  11.261051          11.140688       11.276457   \n",
       "\n",
       "   Lasso Lars IC  Random Forest    XGBoost  \n",
       "0      12.100640      12.133759  12.120995  \n",
       "1      11.977517      12.074685  12.041072  \n",
       "2      11.809399      11.861684  11.829997  \n",
       "3      11.851603      11.700799  11.768791  \n",
       "4      11.290995      11.350956  11.275813  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_validation_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'alpha1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-89736622d44a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Now fit the meta model and generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmeta_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRobustScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00000001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.000005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmeta_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_validation_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'alpha1'"
     ]
    }
   ],
   "source": [
    "drop = ['Bayesian Ridge']\n",
    "stacked_validation_train.drop(drop, axis=1, inplace=True)\n",
    "stacked_test_train.drop(drop, axis=1, inplace=True)\n",
    "\n",
    "# Now fit the meta model and generate predictions\n",
    "meta_model = make_pipeline(RobustScaler(), BayesianRidge(n_iter=200,alpha_1=0.00000001, alpha_2 = 0.000005, copy_X = True,tol = 0.00001,lambda_1=0.000005, lambda_2=0.00000001))\n",
    "meta_model.fit(stacked_validation_train, y_test)\n",
    "\n",
    "meta_model_pred = np.expm1(meta_model.predict(stacked_test_train))\n",
    "print(\"Meta-model trained and applied!...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 KernelRidge final results predicted added to table...\n",
      "2 ElasticNet final results predicted added to table...\n",
      "3 Lasso final results predicted added to table...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07242200317840997, tolerance: 0.06483051719467418\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 GradientBoostingRegressor final results predicted added to table...\n",
      "5 BayesianRidge final results predicted added to table...\n",
      "6 LassoLarsIC final results predicted added to table...\n",
      "7 RandomForestRegressor final results predicted added to table...\n",
      "[15:51:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "8 XGBRegressor final results predicted added to table...\n",
      "--------------------------------------------------\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KernelRidge</th>\n",
       "      <th>ElasticNet</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <th>Lasso Lars IC</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116165.042816</td>\n",
       "      <td>116222.274881</td>\n",
       "      <td>114280.960422</td>\n",
       "      <td>113297.207378</td>\n",
       "      <td>115649.645999</td>\n",
       "      <td>115954.663882</td>\n",
       "      <td>95313.919424</td>\n",
       "      <td>84182.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165566.174249</td>\n",
       "      <td>165536.500003</td>\n",
       "      <td>167359.276660</td>\n",
       "      <td>170387.469359</td>\n",
       "      <td>162850.108492</td>\n",
       "      <td>165034.917900</td>\n",
       "      <td>167119.383260</td>\n",
       "      <td>165122.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182835.846525</td>\n",
       "      <td>183178.642507</td>\n",
       "      <td>183863.479234</td>\n",
       "      <td>179446.976769</td>\n",
       "      <td>182338.325236</td>\n",
       "      <td>182893.715263</td>\n",
       "      <td>182581.144231</td>\n",
       "      <td>178307.15625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195119.625732</td>\n",
       "      <td>195176.634815</td>\n",
       "      <td>196040.573523</td>\n",
       "      <td>196533.333994</td>\n",
       "      <td>191211.857709</td>\n",
       "      <td>194470.498878</td>\n",
       "      <td>191611.914783</td>\n",
       "      <td>188379.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187431.539872</td>\n",
       "      <td>186998.377290</td>\n",
       "      <td>187700.950945</td>\n",
       "      <td>180938.577798</td>\n",
       "      <td>186516.324482</td>\n",
       "      <td>187640.347532</td>\n",
       "      <td>181704.004026</td>\n",
       "      <td>178857.25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     KernelRidge     ElasticNet          Lasso  Gradient Boosting  \\\n",
       "0  116165.042816  116222.274881  114280.960422      113297.207378   \n",
       "1  165566.174249  165536.500003  167359.276660      170387.469359   \n",
       "2  182835.846525  183178.642507  183863.479234      179446.976769   \n",
       "3  195119.625732  195176.634815  196040.573523      196533.333994   \n",
       "4  187431.539872  186998.377290  187700.950945      180938.577798   \n",
       "\n",
       "   Bayesian Ridge  Lasso Lars IC  Random Forest       XGBoost  \n",
       "0   115649.645999  115954.663882   95313.919424   84182.28125  \n",
       "1   162850.108492  165034.917900  167119.383260  165122.37500  \n",
       "2   182338.325236  182893.715263  182581.144231  178307.15625  \n",
       "3   191211.857709  194470.498878  191611.914783  188379.34375  \n",
       "4   186516.324482  187640.347532  181704.004026  178857.25000  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [KernelRidge(), ElasticNet(), Lasso(), GradientBoostingRegressor(), BayesianRidge(), LassoLarsIC(), RandomForestRegressor(), xgb.XGBRegressor()]\n",
    "names = ['KernelRidge', 'ElasticNet', 'Lasso', 'Gradient Boosting', 'Bayesian Ridge', 'Lasso Lars IC', 'Random Forest', 'XGBoost']\n",
    "params_grid = [KR_param_grid, EN_param_grid, LASS_param_grid, GB_param_grid, BR_param_grid, LL_param_grid, RFR_param_grid, XGB_param_grid]\n",
    "final_predictions = pd.DataFrame()\n",
    "\n",
    "row_index=0\n",
    "\n",
    "for alg in models:\n",
    "    \n",
    "    gs_alg = GridSearchCV(alg, param_grid = params_grid[0], cv = shuff, scoring = 'neg_mean_squared_error', n_jobs=-1)\n",
    "    params_grid.pop(0)\n",
    "    \n",
    "    gs_alg.fit(stacked_validation_train, y_test)\n",
    "    gs_best = gs_alg.best_estimator_\n",
    "    final_predictions.insert(loc = row_index, column = names[0], value = np.expm1(gs_best.predict(stacked_test_train)))\n",
    "    print(row_index+1, alg.__class__.__name__, 'final results predicted added to table...')\n",
    "    names.pop(0)\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Done\")\n",
    "    \n",
    "final_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file, created!\n"
     ]
    }
   ],
   "source": [
    "ensemble = meta_model_pred*(1/10) + final_predictions['XGBoost']*(1.5/10) + final_predictions['Gradient Boosting']*(2/10) + final_predictions['Bayesian Ridge']*(1/10) + final_predictions['Lasso']*(1/10) + final_predictions['KernelRidge']*(1/10) + final_predictions['Lasso Lars IC']*(1/10) + final_predictions['Random Forest']*(1.5/10)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_ID\n",
    "submission['SalePrice'] = ensemble\n",
    "submission.to_csv('final_submission.csv',index=False)\n",
    "print(\"Submission file, created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
