{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales_train_validation.csv')\n",
    "price = pd.read_csv('sell_prices.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "submission_format = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'd_' before number in column 'd'\n",
    "calendar['d'] = [i.replace('d_','') for i in calendar['d']]\n",
    "#Generate id in price df\n",
    "price['id'] = price['item_id'] + \"_\" + price['store_id'] + '_validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight for the level 12 series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use second last 28 days since we use last 28 days as test set\n",
    "for day in range(1858,1886):\n",
    "    wk_id = list(calendar[calendar['d']==str(day)]['wm_yr_wk'])[0]\n",
    "    wk_price_df = price[price['wm_yr_wk']==wk_id]\n",
    "    sales = sales.merge(wk_price_df[['sell_price','id']],on=['id'],how='inner')\n",
    "    #Unit sales means the amount of money made at that day. It's trivial to see since Total money = sell_price * num of sales\n",
    "    sales['unit_sales_' + str(day)] = sales['sell_price'] * sales['d_'+str(day)]\n",
    "    sales.drop(['sell_price'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum of all unit_sales\n",
    "sales['dollar_sales'] = sales[[c for c in sales.columns if c.find('unit_sales')==0]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we drop all unit_sales columns\n",
    "sales.drop([c for c in sales.columns if c.find('unit_sales')==0],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['weight'] = sales['dollar_sales'] / sales['dollar_sales'].sum()\n",
    "sales.drop('dollar_sales',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['weight'] /= 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 1920)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer forecast for any level??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making agg_df\n",
    "def make_agg_df(forecast=False):\n",
    "    agg_df = pd.DataFrame(sales[[c for c in sales.columns if c.find('d_')==0]].sum()).transpose()\n",
    "    if forecast:\n",
    "        agg_df = pd.DataFrame(sales[[c for c in sales.columns if c.find('d_')==0 or c.find('F_')==0]].sum()).transpose()\n",
    "    id_cols = ['item_id','dept_id','cat_id','store_id','state_id']\n",
    "    for col in id_cols:\n",
    "        agg_df[col] = 'all'\n",
    "    agg_df['level']=1\n",
    "    agg_df['weight']=1/12\n",
    "    column_agg = agg_df.columns\n",
    "    \n",
    "    level_groupings = {2:['state_id'],3:['store_id'],4:['cat_id'],\n",
    "                   5:['dept_id'],6:['state_id','cat_id'],\n",
    "                   7:['state_id','dept_id'],8:['store_id','cat_id'],\n",
    "                   9:['store_id','dept_id'],10:['item_id'],\n",
    "                   11:['item_id','state_id']}\n",
    "    \n",
    "    #Automate the process of appending time series of different level of aggs into agg_df\n",
    "    for level in level_groupings:\n",
    "        df = sales.groupby(by=level_groupings[level]).sum().reset_index(drop=True)\n",
    "        df['level'] = level\n",
    "        for c in column_agg:\n",
    "            if c not in df.columns:\n",
    "                df[c] = 'all'\n",
    "        agg_df = agg_df.append(df[column_agg])\n",
    "    del df\n",
    "    \n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = make_agg_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30490 12350 42840\n"
     ]
    }
   ],
   "source": [
    "print(sales.shape[0],agg_df.shape[0],sales.shape[0]+agg_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000007"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df['weight'].sum() + sales['weight'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top down approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the last 28 day's mean as I did in another notebook\n",
    "sales['last28_mean'] = sales[[c for c in sales.columns if c.find('d_')==0 and\\\n",
    "    int(c.split('_')[1]) in range(1858,1886)] + ['id']].set_index('id').transpose().mean().reset_index()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in range(1,10):\n",
    "    #1. make forecast for this level\n",
    "    this_level_df = agg_df[agg_df['level']==l].copy()\n",
    "    for d in range(1,29):\n",
    "        this_level_df['F_'+str(l)+\"_\"+str(1885+d)] = this_level_df['d_'+str(1885+d-28)]\n",
    "    \n",
    "    #Distribute foreast to all level 12 series\n",
    "    #Find coluns doens't contain 'all'\n",
    "    important_column_ids = list(this_level_df[id_cols].columns[this_level_df[id_cols].nunique()!=1])\n",
    "    this_level_df.reset_index(drop=True,inplace=True)\n",
    "    for i, row in this_level_df.iterrows():\n",
    "        if len(important_column_ids) == 0:\n",
    "            level_mean_with_cond = this_level_df[[c for c in sales.columns if c.find('d_')==0 and \\\n",
    "                                                 int(c.split('_')[1]) in range(1858,1886)]].transpose().mean()[0]\n",
    "            proportion = sales['last28_mean'] / level_mean_with_cond\n",
    "            for d in range(1,29):\n",
    "                sales['F_' + str(l) + \"_\" + str(1885 + d)] = list(this_level_df['F_' + str(l) + '_' + str(1885+d)])[0] * proportion\n",
    "        else:\n",
    "            cond = True\n",
    "            for col in important_column_ids:\n",
    "                cond = cond & (sales[col] == row[col])\n",
    "            level_mean_with_cond = this_level_df[[c for c in sales.columns if c.find('d_')==0 and \\\n",
    "                                                 int(c.split('_')[1]) in range(1858,1886)]].transpose().mean()[i]\n",
    "            proportion = sales['last28_mean'] / level_mean_with_cond\n",
    "            for d in range(1,29):\n",
    "                sales.loc[cond,'F_' + str(l) + \"_\" + str(1885 + d)] = list(this_level_df['F_' + str(l) + '_' + str(1885+d)])[0] * proportion\n",
    "#remake agg_df\n",
    "agg_df = make_agg_df(forecast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSSE Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 28\n",
    "n = 1885\n",
    "def rmsse(ground_truth, forecast, train_series, axis=1):\n",
    "    assert axis == 0 or axis == 1\n",
    "    if axis == 1:\n",
    "        #Using axis = 1 we must guarantee these are matrices and not arrays\n",
    "        assert ground_truth.shape[1] > 1 and forecast.shape[1] > 1 and train_series.shape[1] > 1\n",
    "    numerator = ((ground_truth - forecast) ** 2).sum(axis=axis)\n",
    "    if axis == 1:\n",
    "        denominator = 1/(n-1) * ((train_series[:,1:]-train_series[:,:-1]) ** 2).sum(axis=axis)\n",
    "    else:\n",
    "        denominator = 1/(n-1) * ((train_series[1:]-train_series[:-1]) ** 2).sum(axis=axis)\n",
    "    return (1/h * numerator/denominator) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When calling .find(a) == 0 that means a has been found\n",
    "train_series_cols = [c for c in sales.columns if c.find('d_')==0][:-28]\n",
    "ground_truth_cols = [c for c in sales.columns if c.find('d_')==0][-28:]\n",
    "forecast_cols_dict = {}\n",
    "for i in range(1,10):\n",
    "    forecast_cols_dict[i] = [c for c in sales.columns if c.find('F_'+str(i)+'_')==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    sales['rmsse_'+str(i)] = rmsse(np.array(sales[ground_truth_cols]),np.array(sales[forecast_cols_dict[i]]),np.array(sales[train_series_cols]))\n",
    "    agg_df['rmsse_'+str(i)] = rmsse(np.array(agg_df[ground_truth_cols]),np.array(agg_df[forecast_cols_dict[i]]),np.array(agg_df[train_series_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    sales['wrmsse_'+str(i)] = sales['weight'] * sales['rmsse_'+str(i)]\n",
    "    agg_df['wrmsse_'+str(i)] = agg_df['weight'] * agg_df['rmsse_'+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate by level 1:\n",
      "0.7526969415454309\n",
      "\n",
      "\n",
      "Aggregate by level 2:\n",
      "0.7705207147160125\n",
      "\n",
      "\n",
      "Aggregate by level 3:\n",
      "0.8513445481111834\n",
      "\n",
      "\n",
      "Aggregate by level 4:\n",
      "0.7582245698757156\n",
      "\n",
      "\n",
      "Aggregate by level 5:\n",
      "1.135816499618113\n",
      "\n",
      "\n",
      "Aggregate by level 6:\n",
      "0.8066315193102094\n",
      "\n",
      "\n",
      "Aggregate by level 7:\n",
      "1.149955673701807\n",
      "\n",
      "\n",
      "Aggregate by level 8:\n",
      "0.8645618277353193\n",
      "\n",
      "\n",
      "Aggregate by level 9:\n",
      "1.3224991470261527\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print('Aggregate by level',str(i)+\":\")\n",
    "    print(sales['wrmsse_'+str(i)].sum()+agg_df['wrmsse_'+str(i)].sum())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_format(df):\n",
    "    #Rename columns\n",
    "    sub_cols = [f'F{i}' for i in range(1,29)]\n",
    "    df.columns = sub_cols\n",
    "    \n",
    "    #Required ids\n",
    "    validation_ids = sales['id'].values\n",
    "    evaluation_ids = [i.replace('validation', 'evaluation') for i in validation_ids]\n",
    "    ids = np.concatenate([validation_ids, evaluation_ids])\n",
    "    \n",
    "    predictions = pd.DataFrame(ids, columns=['id'])\n",
    "    forecast = pd.concat([df] * 2).reset_index(drop=True)\n",
    "    predictions = pd.concat([predictions, forecast], axis=1)\n",
    "    predictions = predictions.set_index('id')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = sales[[c for c in sales.columns if c.find('F_')==0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_as_last_28 = sub_format(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_as_last_28.to_csv('last_28.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['last28_mean'] = sales[[c for c in sales.columns if c.find('d_')==0 and\\\n",
    "    int(c.split('_')[1]) in range(1886,1914)] + ['id']].set_index('id').transpose().mean().reset_index()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_mean = agg_df[[c for c in sales.columns if c.find('d_')==0 and\\\n",
    "                      int(c.split('_')[1]) in range(1886,1914)]].transpose().mean().reset_index()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python demo\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "submit_df = sales[['id']]\n",
    "for i in range(1,29):\n",
    "    proportion = sales['last28_mean'] / level_1_mean\n",
    "    submit_df['F'+str(i)] = agg_df[agg_df['level']==1]['d_'+str(1885+i)][0] * proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python demo\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "submit_df.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_td = sub_format(submit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_td.to_csv('AR_td.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
